{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc, balanced_accuracy_score, accuracy_score, f1_score, roc_auc_score, confusion_matrix, classification_report\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\guerra\\AppData\\Local\\Temp\\ipykernel_14444\\824282083.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  doy_column['doy_sin'] = np.sin(2 * np.pi * doy_column['doy'] / 365)\n",
      "C:\\Users\\guerra\\AppData\\Local\\Temp\\ipykernel_14444\\824282083.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  doy_column['doy_cos'] = np.cos(2 * np.pi * doy_column['doy'] / 365)\n"
     ]
    }
   ],
   "source": [
    "model_input = pd.read_csv(\"data/sp_training_data.csv\")\n",
    "model_input.rename(columns={'nmin_90' : 'leach'}, inplace = True)\n",
    "\n",
    "# Separate columns\n",
    "crop_column = model_input[['crop']]\n",
    "doy_column = model_input[['doy']]\n",
    "\n",
    "# Nmin conversion to binary\n",
    "threshold = model_input['leach'].mean()\n",
    "nmin_column = (model_input['leach'] > threshold).astype(int)\n",
    "\n",
    "# Transform DOY into two dimensions using sine and cosine\n",
    "doy_column['doy_sin'] = np.sin(2 * np.pi * doy_column['doy'] / 365)\n",
    "doy_column['doy_cos'] = np.cos(2 * np.pi * doy_column['doy'] / 365)\n",
    "\n",
    "# One-hot encode the 'crop' column\n",
    "encoder = OneHotEncoder(sparse=False)\n",
    "crop_encoded = encoder.fit_transform(crop_column)\n",
    "crop_df = pd.DataFrame(crop_encoded, columns=encoder.get_feature_names_out(['crop']))\n",
    "\n",
    "# Drop 'crop' and 'doy' columns and the specified 'field' from the original DataFrame\n",
    "fields = model_input.drop(['crop', 'doy', 'leach'], axis=1)\n",
    "\n",
    "# Scale the remaining numerical features\n",
    "scaler = StandardScaler(with_mean=False)\n",
    "scaled_fields = scaler.fit_transform(fields)\n",
    "scaled_fields_df = pd.DataFrame(scaled_fields, columns=fields.columns)\n",
    "\n",
    "# Concatenate the transformed 'crop', 'doy', and scaled numerical features\n",
    "final_df = pd.concat([doy_column[['doy_sin', 'doy_cos']], crop_df, scaled_fields_df, nmin_column], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drops bands not in 4band spectrum and indices from them\n",
    "fourband = final_df.drop(['band_1', 'band_3', 'band_5', 'band_7', 'NDRE', 'MCARI', 'LCCI'], axis = 1)\n",
    "\n",
    "# drops rows with NA present (only occurs in 4band rows for extra bands)\n",
    "NAmask  = final_df.apply(lambda x: x.notna().all(), axis=1)\n",
    "eightband = final_df[NAmask]\n",
    "\n",
    "# drops crop columns and bands not in 4band spectrum and indices from them \n",
    "nocrop = pd.concat([doy_column[['doy_sin', 'doy_cos']], scaled_fields_df, nmin_column], axis=1)\n",
    "nocrop_four = nocrop.drop(['band_1', 'band_3', 'band_5', 'band_7', 'NDRE', 'MCARI', 'LCCI'], axis = 1)\n",
    "\n",
    "# drops crop columns and rows with NA present (only occurs in 4band rows for extra bands))\n",
    "nocrop_eight = nocrop[NAmask]\n",
    "\n",
    "dfs = [\n",
    "    [fourband, 'fourband'], \n",
    "    [eightband, 'eightband']\n",
    "    # [nocrop_four, 'nocrop four'],\n",
    "    # [nocrop_eight, 'nocrop eight']\n",
    "    ]\n",
    "\n",
    "yvar = 'leach'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model: Logistic Regression\n",
      "----------------------------------------\n",
      "Balanced Accuracy: fourband\n",
      "0.625\n",
      "Balanced Accuracy: eightband\n",
      "0.6136363636363636\n",
      "\n",
      "Model: SVM\n",
      "----------------------------------------\n",
      "Balanced Accuracy: fourband\n",
      "0.5\n",
      "Balanced Accuracy: eightband\n",
      "0.5\n",
      "\n",
      "Model: KNN\n",
      "----------------------------------------\n",
      "Balanced Accuracy: fourband\n",
      "0.6875\n",
      "Balanced Accuracy: eightband\n",
      "0.75\n",
      "\n",
      "Model: Decision Tree\n",
      "----------------------------------------\n",
      "Balanced Accuracy: fourband\n",
      "0.7083333333333333\n",
      "Balanced Accuracy: eightband\n",
      "0.3181818181818182\n",
      "\n",
      "Model: Random Forest\n",
      "----------------------------------------\n",
      "Balanced Accuracy: fourband\n",
      "0.6458333333333334\n",
      "Balanced Accuracy: eightband\n",
      "0.5\n",
      "\n",
      "Model: Gradient Boosting\n",
      "----------------------------------------\n",
      "Balanced Accuracy: fourband\n",
      "0.6458333333333334\n",
      "Balanced Accuracy: eightband\n",
      "0.36363636363636365\n",
      "\n",
      "Model: AdaBoost\n",
      "----------------------------------------\n",
      "Balanced Accuracy: fourband\n",
      "0.6875\n",
      "Balanced Accuracy: eightband\n",
      "0.45454545454545453\n"
     ]
    }
   ],
   "source": [
    "models = [\n",
    "    (\"Logistic Regression\", LogisticRegression(max_iter=10000)), # increased max_iter for convergence\n",
    "    (\"SVM\", SVC(probability=True)), # set probability=True to ensure you can use methods like predict_proba if needed\n",
    "    (\"KNN\", KNeighborsClassifier()),\n",
    "    (\"Decision Tree\", DecisionTreeClassifier(random_state=42)),\n",
    "    (\"Random Forest\", RandomForestClassifier(random_state=42)),\n",
    "    (\"Gradient Boosting\", GradientBoostingClassifier(random_state=42)),\n",
    "    (\"AdaBoost\", AdaBoostClassifier(random_state=42))\n",
    "]\n",
    "\n",
    "for model_name, model_instance in models:\n",
    "    print(f\"\\nModel: {model_name}\\n{'-'*40}\")\n",
    "    for data, name in dfs:\n",
    "        x = data.drop(yvar, axis=1)\n",
    "        y = data[[yvar]]\n",
    "        cn = data.columns #column names\n",
    "        n = data.shape[0] #nrows\n",
    "        # Split the data\n",
    "        X_train, X_test, y_train, y_test = train_test_split(x, y.values.ravel(), test_size=0.2, random_state=42)\n",
    "        # Train the model\n",
    "        model_instance.fit(X_train, y_train)\n",
    "        # Predict on the test set\n",
    "        y_pred = model_instance.predict(X_test)\n",
    "        # Compute the confusion matrix\n",
    "        # conf_mat = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "        # Generate the classification report\n",
    "        # class_report = classification_report(y_test, y_pred)\n",
    "        balacc = balanced_accuracy_score(y_test, y_pred)\n",
    "\n",
    "        print(\"Balanced Accuracy:\", name)\n",
    "        print(balacc)\n",
    "\n",
    "        # # Visualize the confusion matrix (Optional)\n",
    "        # plt.figure(figsize=(8, 6))\n",
    "        # sns.heatmap(conf_mat, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "        # plt.xlabel('Predicted')\n",
    "        # plt.ylabel('Actual')\n",
    "        # plt.title('Confusion Matrix')\n",
    "        # plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gis-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
